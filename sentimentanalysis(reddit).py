# -*- coding: utf-8 -*-
"""SentimentAnalysis(reddit).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18xYZytPfCd41iT6ZjTRVI7gPhQKm6Y_y
"""

!pip install nltk praw

import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import praw

nltk.download('vader_lexicon')

#Initializing sentiment analyzer
sia = SentimentIntensityAnalyzer()


#details in readme files, for how to get these info
reddit_id = 'YOUR_REDDIT_ID'
reddit_secret = 'YOUR_REDDIT_SECRET'
reddit_agent = "YOUR_REDDIT_AGENT"

reddit = praw.Reddit(
    client_id=reddit_id,  #Client ID
    client_secret=reddit_secret,  #Client Secret
    user_agent=reddit_agent  # User Agent
)


def fetch_and_analyze_post_comments(url=None, subreddit_name=None, limit=10): #limit can be flexible
    if url:
        submission = reddit.submission(url=url)
    elif subreddit_name:
        subreddit = reddit.subreddit(subreddit_name)
        try:
            # This will raise an exception if the subreddit is invalid
            if not subreddit.id:
                print(f"X Subreddit '{subreddit_name}' is invalid or private.")
                return
        except Exception as e:
            print(f"X Error accessing subreddit: {e}")
            return
        try:
          submission = next(subreddit.hot(limit=1))  # take the hot post
        except StopIteration:
          try:
            submission = next(subreddit.new(limit=1)) # take the new posts
          except StopIteration:
            try:
              submission = next(subreddit.top(limit=1)) # take the top posts
            except StopIteration:
              print("No posts found in the subreddit.")
              return

              ''' we take the order of posts as hot, new, top, to ensure the best quality of posts'''

    else:
        print("Please provide a subreddit or a post URL.")
        return

    print(f"\nAnalyzing Post: {submission.title}\n")

    submission.comments.replace_more(limit=0)
    comments = submission.comments.list()[:limit]

    sentiment_summary = {'positive': 0, 'neutral': 0, 'negative': 0}

    for i, comment in enumerate(comments):
        text = comment.body
        print(f"Comment {i+1}: {text}...")  # Print first 100 chars
        scores = sia.polarity_scores(text)
        print(f"Scores: {scores}")

        if scores['compound'] >= 0.05:
            sentiment_summary['positive'] += 1
        elif scores['compound'] <= -0.05:
            sentiment_summary['negative'] += 1
        else:
            sentiment_summary['neutral'] += 1
        print()

    print("ðŸ“Š Sentiment Summary:")
    print(f"Positive: {sentiment_summary['positive']}")
    print(f"Neutral:  {sentiment_summary['neutral']}")
    print(f"Negative: {sentiment_summary['negative']}")

print("Enter subredit name")# only subredit name for now
fetch_and_analyze_post_comments(subreddit_name=input())